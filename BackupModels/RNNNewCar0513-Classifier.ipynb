{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import data, io, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "width = 224\n",
    "height = 168\n",
    "# Import Labels\n",
    "labels = []\n",
    "imagePaths = []\n",
    "lastTrackingAngle = 0\n",
    "lastSpeed = 0\n",
    "for i in range(20,41):\n",
    "    fname = \"/home/matt/Desktop/RainierDrive/AccelerationData/capture\"+str(i)+\"/accelClass.txt\"\n",
    "    base = \"/home/matt/Desktop/RainierDrive/AccelerationData/capture\"+str(i) + \"/\"\n",
    "    \n",
    "    if(not os.path.isfile(fname)):\n",
    "        print(\"Could not find file for capture \", str(i))\n",
    "        continue\n",
    "    with open(fname) as f:\n",
    "        content = f.readlines()\n",
    "        for line in content:\n",
    "            line = line.split(\",\")\n",
    "            speedString = (line[1].split(\" \"))[2]\n",
    "            speed = float(speedString)\n",
    "            trackingAngleString = (line[8].split(\" \"))[2]\n",
    "            trackingAngle = float(trackingAngleString)\n",
    "            deltaTrackingAngle = trackingAngle - lastTrackingAngle\n",
    "            deltaSpeed = speed - lastSpeed\n",
    "            lastTrackingAngle = trackingAngle\n",
    "            lastSpeed = speed\n",
    "            filePath = (line[10])\n",
    "            if speed > 0 and abs(deltaTrackingAngle) > 0 and abs(deltaTrackingAngle) < 7:\n",
    "                if(deltaTrackingAngle>0):\n",
    "                    deltaTrackingAngle = 1\n",
    "                else:\n",
    "                    deltaTrackingAngle = -1\n",
    "                speed = speed/10\n",
    "                speed = int(speed)\n",
    "                speedArray = np.zeros((8))\n",
    "                speedArray[speed] = 1\n",
    "                labels.append(speedArray)\n",
    "                #labels.append(deltaTrackingAngle)\n",
    "                #print speed\n",
    "                #print trackingAngle\n",
    "                picturePath = base+filePath\n",
    "                #print picturePath\n",
    "                imagePaths.append(picturePath)\n",
    "\n",
    "trainingIndex = int(len(imagePaths)/1.4)\n",
    "print trainingIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel, hsv_value\n",
    "from skimage import filters\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel, hsv_value\n",
    "from skimage import filters\n",
    "import operator\n",
    "from operator import sub\n",
    "\n",
    "\n",
    "@adapt_rgb(each_channel)\n",
    "def sobel_each(image):\n",
    "    return filters.sobel(image)\n",
    "\n",
    "def as_gray(image_filter, image, *args, **kwargs):\n",
    "    gray_image = rgb2gray(image)\n",
    "    return image_filter(gray_image, *args, **kwargs)\n",
    "\n",
    "@adapt_rgb(as_gray)\n",
    "def sobel_gray(image):\n",
    "    return filters.sobel(image)\n",
    "\n",
    "\n",
    "\n",
    "images = np.zeros((len(imagePaths),height,width))\n",
    "print(images.shape)\n",
    "threadCount = 20\n",
    "import threading\n",
    "\n",
    "def worker(loadPath, imageIndex):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    image = skimage.data.imread(loadPath)\n",
    "    image = skimage.transform.resize(image, (height, width), mode='reflect')\n",
    "    edges = sobel_gray(image)\n",
    "    images[imageIndex] = edges\n",
    "    return edges, imageIndex\n",
    "\n",
    "for imNum in range(0,len(imagePaths),threadCount):\n",
    "    threads = []\n",
    "    for i in range(threadCount):\n",
    "        if(imNum+i >= len(imagePaths)):\n",
    "            continue\n",
    "        loadPath = imagePaths[imNum+i]\n",
    "        t = threading.Thread(target=worker, args=(loadPath,imNum+i))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = np.asarray(images)\n",
    "images = images.reshape(len(images),1,width*height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "images = np.array(images)\n",
    "print(\"labels: \", labels.shape, \"\\nimages: \", images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxLength = trainingIndex\n",
    "global currentPos\n",
    "currentPos = 0\n",
    "def next(batch_size):\n",
    "    \"\"\" Return a batch of data. When dataset end is reached, start over.\n",
    "    \"\"\"\n",
    "    #if self.batch_id == len(self.data):\n",
    "    #    self.batch_id = 0\n",
    "    #batch_data = (self.data[self.batch_id:min(self.batch_id +\n",
    "    #                                          batch_size, len(self.data))])\n",
    "    #batch_labels = (self.labels[self.batch_id:min(self.batch_id +\n",
    "    #                                          batch_size, len(self.data))])\n",
    "    #batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\n",
    "    #                                          batch_size, len(self.data))])\n",
    "    #self.batch_id = min(self.batch_id + batch_size, len(self.data))\n",
    "    global currentPos\n",
    "    currentPos = currentPos + batch_size\n",
    "    maxPos = currentPos + batch_size\n",
    "    if(maxPos>maxLength):\n",
    "        currentPos = 0\n",
    "        maxPos = currentPos + batch_size\n",
    "    batch_data = (images[currentPos:maxPos])\n",
    "    batch_labels = (labels[currentPos:maxPos])\n",
    "    return batch_data, batch_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxTestingLength = len(labels)\n",
    "global currentTestingPos\n",
    "global minIndex \n",
    "minIndex = trainingIndex\n",
    "currentTestingPos = minIndex\n",
    "\n",
    "def nextTesting(batch_size):\n",
    "    global currentTestingPos\n",
    "    global minIndex\n",
    "    currentTestingPos = currentTestingPos + batch_size\n",
    "    maxPos = currentTestingPos + batch_size\n",
    "    if(maxPos>maxTestingLength):\n",
    "        currentTestingPos = minIndex\n",
    "        maxPos = currentTestingPos + batch_size\n",
    "    batch_data = (images[currentTestingPos:maxPos])\n",
    "    batch_labels = (labels[currentTestingPos:maxPos])\n",
    "    return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(128)\n",
    "print(x.shape)\n",
    "print(y)\n",
    "\n",
    "x, y = nextTesting(128)\n",
    "print(x.shape)\n",
    "print(y)\n",
    "\n",
    "cellInitialized = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "Long Short Term Memory paper: http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "'''\n",
    "To classify images using a recurrent neural network, we consider every image\n",
    "row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n",
    "handle 28 sequences of 28 steps for every sample.\n",
    "'''\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_iters = 160000\n",
    "batch_size = 256\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = width # MNIST data input (img shape: 28*28)\n",
    "n_steps = height # timesteps\n",
    "n_hidden = 1024 # hidden layer num of features\n",
    "n_classes = 8 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    print(x.shape)\n",
    "    x = tf.unstack(x, n_steps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "def BiRNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `bidirectional_rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, n_steps, 1)\n",
    "\n",
    "    # Define lstm cells with tensorflow\n",
    "    # Forward direction cell\n",
    "    lstm_fw_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    # Backward direction cell\n",
    "    lstm_bw_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    try:\n",
    "        outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                              dtype=tf.float32)\n",
    "    except Exception: # Old TensorFlow version only returns outputs not states\n",
    "        outputs = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                        dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "\n",
    "# Calculate accuracy\n",
    "modelaccuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 9000000\n",
    "display_step = 10\n",
    "step = 1\n",
    "# Keep training until reach max iterations\n",
    "while step * batch_size < training_iters:\n",
    "    batch_x, batch_y = next(batch_size)\n",
    "    # Reshape data to get 28 seq of 28 elements\n",
    "    batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "    batch_y = batch_y.reshape((batch_size, 8))\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "    if step % display_step == 0:\n",
    "        # Calculate batch accuracy\n",
    "        mc = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "        acc = sess.run(modelaccuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(mc) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc))\n",
    "    step += 1\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speed accuracy\n",
    "\n",
    "step = 1\n",
    "totalMAE = 0\n",
    "correctDirectionCount = 0\n",
    "totalCount = 0\n",
    "threshold = 12\n",
    "# Calculate accuracy for 128 mnist test images\n",
    "while step * batch_size < (len(images)-trainingIndex):\n",
    "    test_data, test_label = nextTesting(batch_size)\n",
    "    test_data = test_data.reshape((batch_size,n_steps, n_input))\n",
    "    test_label = test_label.reshape((batch_size, 8))\n",
    "    predAccuracy = sess.run(modelaccuracy, feed_dict={x: test_data, y: test_label})\n",
    "    totalMAE = totalMAE + predAccuracy\n",
    "    results = sess.run(pred, feed_dict={x: test_data})\n",
    "    for i in range(0,len(results)):\n",
    "        print (\"Guess:\",str(results[i]),\"Actual: \",str(test_label[i]))\n",
    "    print(\"Testing Accuracy:\", predAccuracy)\n",
    "    print(str(totalMAE/(step)))\n",
    "    step+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Speed accuracy\n",
    "\n",
    "step = 1\n",
    "totalMAE = 0\n",
    "correctDirectionCount = 0\n",
    "totalCount = 0\n",
    "threshold = 12\n",
    "# Calculate accuracy for 128 mnist test images\n",
    "while step * batch_size < (len(images)-trainingIndex):\n",
    "    test_data, test_label = nextTesting(batch_size)\n",
    "    test_data = test_data.reshape((batch_size, n_steps, n_input))\n",
    "    predAccuracy = sess.run(accuracy, feed_dict={x: test_data, y: test_label})\n",
    "    results = sess.run(pred, feed_dict={x: test_data})\n",
    "    #print(results)\n",
    "    #print(test_label)\n",
    "    for i in range(0,len(results)):\n",
    "        element = abs(results[i] - test_label[i])\n",
    "        if(abs(test_label[i])>75):\n",
    "            continue\n",
    "        totalCount+=1\n",
    "        print(\"Actual:\", test_label[i],\"Guess:\",results[i],\"Delta\",element)\n",
    "        if element < threshold:\n",
    "            correctDirectionCount+=1\n",
    "    totalMAE += predAccuracy\n",
    "    print(\"Testing Accuracy:\", predAccuracy)\n",
    "    step+=1\n",
    "print(\"Total MAE: \", (totalMAE/(step-1)))\n",
    "print(\"Turn percentage\", (totalCount/((step-1) * batch_size)))\n",
    "print (\"Correct Speed within threshold percentage \",(correctDirectionCount/totalCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a saver object which will save all the variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, save the graph\n",
    "saver.save(sess, 'rnnclassspeed',global_step=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
