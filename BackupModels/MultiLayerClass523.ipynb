{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import data, io, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "width = 224\n",
    "height = 168\n",
    "# Import Labels\n",
    "labels = []\n",
    "imagePaths = []\n",
    "lastTrackingAngle = 0\n",
    "lastSpeed = 0\n",
    "for i in range(20,41):\n",
    "    fname = \"/home/matt/Desktop/RainierDrive/AccelerationData/capture\"+str(i)+\"/accelClass.txt\"\n",
    "    base = \"/home/matt/Desktop/RainierDrive/AccelerationData/capture\"+str(i) + \"/\"\n",
    "    \n",
    "    if(not os.path.isfile(fname)):\n",
    "        print(\"Could not find file for capture \", str(i))\n",
    "        continue\n",
    "    with open(fname) as f:\n",
    "        content = f.readlines()\n",
    "        for line in content:\n",
    "            line = line.split(\",\")\n",
    "            speedString = (line[1].split(\" \"))[2]\n",
    "            speed = float(speedString)\n",
    "            trackingAngleString = (line[8].split(\" \"))[2]\n",
    "            trackingAngle = float(trackingAngleString)\n",
    "            deltaTrackingAngle = trackingAngle - lastTrackingAngle\n",
    "            deltaSpeed = speed - lastSpeed\n",
    "            lastTrackingAngle = trackingAngle\n",
    "            lastSpeed = speed\n",
    "            filePath = (line[10])\n",
    "            if speed > 0 and abs(deltaTrackingAngle) > 0 and abs(deltaTrackingAngle) < 7:\n",
    "                if(deltaTrackingAngle>0):\n",
    "                    deltaTrackingAngle = 1\n",
    "                else:\n",
    "                    deltaTrackingAngle = -1\n",
    "                speed = speed/10\n",
    "                speed = int(speed)\n",
    "                speedArray = np.zeros((8))\n",
    "                speedArray[speed] = 1\n",
    "                labels.append(speedArray)\n",
    "                #labels.append(deltaTrackingAngle)\n",
    "                #print speed\n",
    "                #print trackingAngle\n",
    "                picturePath = base+filePath\n",
    "                #print picturePath\n",
    "                imagePaths.append(picturePath)\n",
    "\n",
    "trainingIndex = int(len(imagePaths)/1.4)\n",
    "print trainingIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel, hsv_value\n",
    "from skimage import filters\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel, hsv_value\n",
    "from skimage import filters\n",
    "import operator\n",
    "from operator import sub\n",
    "\n",
    "\n",
    "@adapt_rgb(each_channel)\n",
    "def sobel_each(image):\n",
    "    return filters.sobel(image)\n",
    "\n",
    "def as_gray(image_filter, image, *args, **kwargs):\n",
    "    gray_image = rgb2gray(image)\n",
    "    return image_filter(gray_image, *args, **kwargs)\n",
    "\n",
    "@adapt_rgb(as_gray)\n",
    "def sobel_gray(image):\n",
    "    return filters.sobel(image)\n",
    "\n",
    "\n",
    "\n",
    "images = np.zeros((len(imagePaths),height,width,3))\n",
    "print(images.shape)\n",
    "threadCount = 20\n",
    "import threading\n",
    "\n",
    "def worker(loadPath, loadPath2, imageIndex):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    #image = skimage.data.imread(loadPath)\n",
    "    image2 = skimage.data.imread(loadPath2)\n",
    "    #image = skimage.transform.resize(image, (height, width), mode='reflect')\n",
    "    image2 = skimage.transform.resize(image2, (height, width), mode='reflect')\n",
    "    #edges = sobel_each(image)\n",
    "    #edges2 = sobel_each(image2)\n",
    "    #edges3 = edges2+edges\n",
    "    images[imageIndex] = image2\n",
    "    return imageIndex\n",
    "\n",
    "for imNum in range(0,len(imagePaths),threadCount):\n",
    "    threads = []\n",
    "    for i in range(threadCount):\n",
    "        \n",
    "        if(imNum+i >= len(imagePaths)):\n",
    "            continue\n",
    "        if(imNum+1==0):\n",
    "            loadPath = imagePaths[mNum+i]\n",
    "            loadPath2 = imagePaths[imNum+i]\n",
    "        else:\n",
    "            loadPath = imagePaths[imNum+i-1]\n",
    "            loadPath2 = imagePaths[imNum+i]\n",
    "        t = threading.Thread(target=worker, args=(loadPath,loadPath2,imNum+i))\n",
    "        threads.append(t)\n",
    "        t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = images[23]\n",
    "print(images[23])\n",
    "io.imshow(image)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "images = np.asarray(images)\n",
    "images = images.reshape(len(images),1,width*height*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "images = np.array(images)\n",
    "print(\"labels: \", labels.shape, \"\\nimages: \", images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxLength = trainingIndex\n",
    "global currentPos\n",
    "currentPos = 0\n",
    "def next(batch_size):\n",
    "    \"\"\" Return a batch of data. When dataset end is reached, start over.\n",
    "    \"\"\"\n",
    "    #if self.batch_id == len(self.data):\n",
    "    #    self.batch_id = 0\n",
    "    #batch_data = (self.data[self.batch_id:min(self.batch_id +\n",
    "    #                                          batch_size, len(self.data))])\n",
    "    #batch_labels = (self.labels[self.batch_id:min(self.batch_id +\n",
    "    #                                          batch_size, len(self.data))])\n",
    "    #batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\n",
    "    #                                          batch_size, len(self.data))])\n",
    "    #self.batch_id = min(self.batch_id + batch_size, len(self.data))\n",
    "    global currentPos\n",
    "    currentPos = currentPos + batch_size\n",
    "    maxPos = currentPos + batch_size\n",
    "    if(maxPos>maxLength):\n",
    "        currentPos = 0\n",
    "        maxPos = currentPos + batch_size\n",
    "    batch_data = (images[currentPos:maxPos])\n",
    "    batch_labels = (labels[currentPos:maxPos])\n",
    "    return batch_data, batch_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxTestingLength = len(labels)\n",
    "global currentTestingPos\n",
    "global minIndex \n",
    "minIndex = trainingIndex\n",
    "currentTestingPos = minIndex\n",
    "\n",
    "def nextTesting(batch_size):\n",
    "    global currentTestingPos\n",
    "    global minIndex\n",
    "    currentTestingPos = currentTestingPos + batch_size\n",
    "    maxPos = currentTestingPos + batch_size\n",
    "    if(maxPos>maxTestingLength):\n",
    "        currentTestingPos = minIndex\n",
    "        maxPos = currentTestingPos + batch_size\n",
    "    batch_data = (images[currentTestingPos:maxPos])\n",
    "    batch_labels = (labels[currentTestingPos:maxPos])\n",
    "    return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(128)\n",
    "print(x.shape)\n",
    "print(y)\n",
    "\n",
    "x, y = nextTesting(128)\n",
    "print(x.shape)\n",
    "print(y)\n",
    "\n",
    "cellInitialized = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "Long Short Term Memory paper: http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "'''\n",
    "To classify images using a recurrent neural network, we consider every image\n",
    "row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n",
    "handle 28 sequences of 28 steps for every sample.\n",
    "'''\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 64\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 1280 # 1st layer number of features\n",
    "n_hidden_2 = 640 # 2nd layer number of features\n",
    "n_input = width*height*3 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 8 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "\n",
    "# Calculate accuracy\n",
    "modelaccuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 90000\n",
    "display_step = 10\n",
    "step = 1\n",
    "# Keep training until reach max iterations\n",
    "while step * batch_size < training_iters:\n",
    "    batch_x, batch_y = next(batch_size)\n",
    "    # Reshape data to get 28 seq of 28 elements\n",
    "    batch_x = batch_x.reshape((batch_size, n_input))\n",
    "    batch_y = batch_y.reshape((batch_size, 8))\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "    if step % display_step == 0:\n",
    "        # Calculate batch accuracy\n",
    "        mc = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "        acc = sess.run(modelaccuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(mc) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc))\n",
    "    step += 1\n",
    "print(\"Optimization Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speed accuracy\n",
    "\n",
    "step = 1\n",
    "totalMAE = 0\n",
    "correctDirectionCount = 0\n",
    "totalCount = 0\n",
    "threshold = 12\n",
    "# Calculate accuracy for 128 mnist test images\n",
    "while step * batch_size < (len(images)-trainingIndex):\n",
    "    test_data, test_label = nextTesting(batch_size)\n",
    "    test_data = test_data.reshape((batch_size, n_input))\n",
    "    test_label = test_label.reshape((batch_size, 8))\n",
    "    predAccuracy = sess.run(modelaccuracy, feed_dict={x: test_data, y: test_label})\n",
    "    totalMAE = totalMAE + predAccuracy\n",
    "    results = sess.run(pred, feed_dict={x: test_data})\n",
    "    print(\"Testing Accuracy:\", predAccuracy)\n",
    "    print(str(totalMAE/(step)))\n",
    "    step+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
