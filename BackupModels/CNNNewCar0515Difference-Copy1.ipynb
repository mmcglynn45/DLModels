{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import data, io, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "width = 224\n",
    "height = 168\n",
    "# Import Labels\n",
    "labels = []\n",
    "imagePaths = []\n",
    "lastTrackingAngle = 0\n",
    "lastSpeed = 0\n",
    "for i in range(20,41):\n",
    "    fname = \"/home/matt/Desktop/RainierDrive/AccelerationData/capture\"+str(i)+\"/accelClass.txt\"\n",
    "    base = \"/home/matt/Desktop/RainierDrive/AccelerationData/capture\"+str(i) + \"/\"\n",
    "    \n",
    "    if(not os.path.isfile(fname)):\n",
    "        print(\"Could not find file for capture \", str(i))\n",
    "        continue\n",
    "    with open(fname) as f:\n",
    "        content = f.readlines()\n",
    "        for line in content:\n",
    "            line = line.split(\",\")\n",
    "            speedString = (line[1].split(\" \"))[2]\n",
    "            speed = float(speedString)\n",
    "            trackingAngleString = (line[8].split(\" \"))[2]\n",
    "            trackingAngle = float(trackingAngleString)\n",
    "            deltaTrackingAngle = trackingAngle - lastTrackingAngle\n",
    "            deltaSpeed = speed - lastSpeed\n",
    "            lastTrackingAngle = trackingAngle\n",
    "            lastSpeed = speed\n",
    "            filePath = (line[10])\n",
    "            if speed > 10 and abs(deltaTrackingAngle) > 0 and abs(deltaTrackingAngle) < 7:\n",
    "                if(deltaTrackingAngle>0):\n",
    "                    deltaTrackingAngle = 1\n",
    "                else:\n",
    "                    deltaTrackingAngle = -1\n",
    "                labels.append(speed)\n",
    "                #labels.append(deltaTrackingAngle)\n",
    "                #print speed\n",
    "                #print trackingAngle\n",
    "                picturePath = base+filePath\n",
    "                #print picturePath\n",
    "                imagePaths.append(picturePath)\n",
    "\n",
    "trainingIndex = int(len(imagePaths)/1.4)\n",
    "print trainingIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel, hsv_value\n",
    "from skimage import filters\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel, hsv_value\n",
    "from skimage import filters\n",
    "import operator\n",
    "from operator import sub\n",
    "\n",
    "\n",
    "@adapt_rgb(each_channel)\n",
    "def sobel_each(image):\n",
    "    return filters.sobel(image)\n",
    "\n",
    "def as_gray(image_filter, image, *args, **kwargs):\n",
    "    gray_image = rgb2gray(image)\n",
    "    return image_filter(gray_image, *args, **kwargs)\n",
    "\n",
    "@adapt_rgb(as_gray)\n",
    "def sobel_gray(image):\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "images = np.zeros((len(imagePaths),height,width))\n",
    "print(images.shape)\n",
    "threadCount = 20\n",
    "import threading\n",
    "\n",
    "def worker(loadPath, loadPath2, imageIndex):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    image = skimage.data.imread(loadPath)\n",
    "    image2 = skimage.data.imread(loadPath2)\n",
    "    image = skimage.transform.resize(image, (height, width), mode='reflect')\n",
    "    image2 = skimage.transform.resize(image2, (height, width), mode='reflect')\n",
    "    edges = sobel_gray(image)\n",
    "    edges2 = sobel_gray(image2)\n",
    "    edges3 = edges2-edges\n",
    "    images[imageIndex] = edges2\n",
    "    return edges3, imageIndex\n",
    "\n",
    "for imNum in range(0,len(imagePaths),threadCount):\n",
    "    threads = []\n",
    "    for i in range(threadCount):\n",
    "        \n",
    "        if(imNum+i >= len(imagePaths)):\n",
    "            continue\n",
    "        if(imNum+1==0):\n",
    "            loadPath = imagePaths[mNum+i]\n",
    "            loadPath2 = imagePaths[imNum+i]\n",
    "        else:\n",
    "            loadPath = imagePaths[imNum+i-1]\n",
    "            loadPath2 = imagePaths[imNum+i]\n",
    "        t = threading.Thread(target=worker, args=(loadPath,loadPath2,imNum+i))\n",
    "        threads.append(t)\n",
    "        t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = images[140]\n",
    "print(images[23])\n",
    "io.imshow(image)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "images = np.asarray(images)\n",
    "images = images.reshape(len(images),1,width*height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "images = np.array(images)\n",
    "print(\"labels: \", labels.shape, \"\\nimages: \", images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxLength = trainingIndex\n",
    "global currentPos\n",
    "currentPos = 0\n",
    "def next(batch_size):\n",
    "    \"\"\" Return a batch of data. When dataset end is reached, start over.\n",
    "    \"\"\"\n",
    "    #if self.batch_id == len(self.data):\n",
    "    #    self.batch_id = 0\n",
    "    #batch_data = (self.data[self.batch_id:min(self.batch_id +\n",
    "    #                                          batch_size, len(self.data))])\n",
    "    #batch_labels = (self.labels[self.batch_id:min(self.batch_id +\n",
    "    #                                          batch_size, len(self.data))])\n",
    "    #batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\n",
    "    #                                          batch_size, len(self.data))])\n",
    "    #self.batch_id = min(self.batch_id + batch_size, len(self.data))\n",
    "    global currentPos\n",
    "    currentPos = currentPos + batch_size\n",
    "    maxPos = currentPos + batch_size\n",
    "    if(maxPos>maxLength):\n",
    "        currentPos = 0\n",
    "        maxPos = currentPos + batch_size\n",
    "    batch_data = (images[currentPos:maxPos])\n",
    "    batch_labels = (labels[currentPos:maxPos])\n",
    "    return batch_data, batch_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxTestingLength = len(labels)\n",
    "global currentTestingPos\n",
    "global minIndex \n",
    "minIndex = trainingIndex\n",
    "currentTestingPos = minIndex\n",
    "\n",
    "def nextTesting(batch_size):\n",
    "    global currentTestingPos\n",
    "    global minIndex\n",
    "    currentTestingPos = currentTestingPos + batch_size\n",
    "    maxPos = currentTestingPos + batch_size\n",
    "    if(maxPos>maxTestingLength):\n",
    "        currentTestingPos = minIndex\n",
    "        maxPos = currentTestingPos + batch_size\n",
    "    batch_data = (images[currentTestingPos:maxPos])\n",
    "    batch_labels = (labels[currentTestingPos:maxPos])\n",
    "    return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(128)\n",
    "print(x.shape)\n",
    "print(y)\n",
    "\n",
    "x, y = nextTesting(128)\n",
    "print(x.shape)\n",
    "print(y)\n",
    "\n",
    "cellInitialized = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "Long Short Term Memory paper: http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "'''\n",
    "To classify images using a recurrent neural network, we consider every image\n",
    "row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n",
    "handle 28 sequences of 28 steps for every sample.\n",
    "'''\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 15\n",
    "batch_size = 64\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = width*height # MNIST data input (img shape: 28*28)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "n_classes = 1 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, width, height, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "accuracyFloor = tf.constant(5.0, tf.float32)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.maximum(tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(pred, y)))),accuracyFloor)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# Evaluate model\n",
    "#correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(pred, y))))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 2400000\n",
    "step =0\n",
    "display_step = 150\n",
    "# Keep training until reach max iterations\n",
    "while step * batch_size < training_iters:\n",
    "    batch_x, batch_y = next(batch_size)\n",
    "    # Reshape data to get 28 seq of 28 elements\n",
    "    batch_x = batch_x.reshape((batch_size, n_input))\n",
    "    batch_y = batch_y.reshape((batch_size, 1))\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "    if step % display_step == 0:\n",
    "        # Calculate batch accuracy\n",
    "        acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout })\n",
    "        # Calculate batch loss\n",
    "        cost = sess.run(loss, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(cost) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc))\n",
    "    step += 1\n",
    "print(\"Optimization Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Speed accuracy\n",
    "\n",
    "step = 1\n",
    "totalMAE = 0\n",
    "correctDirectionCount = 0\n",
    "totalCount = 0\n",
    "threshold = 12\n",
    "# Calculate accuracy for 128 mnist test images\n",
    "while step * batch_size < (len(images)-trainingIndex):\n",
    "    test_data, test_label = nextTesting(batch_size)\n",
    "    test_data = test_data.reshape((batch_size, n_input))\n",
    "    test_label = test_label.reshape((batch_size, 1))\n",
    "    predAccuracy = sess.run(accuracy, feed_dict={x: test_data, y: test_label, keep_prob: dropout})\n",
    "    results = sess.run(pred, feed_dict={x: test_data, keep_prob: dropout})\n",
    "    #print(results)\n",
    "    #print(test_label)\n",
    "    for i in range(0,len(results)):\n",
    "        element = abs(results[i] - test_label[i])\n",
    "        if(abs(test_label[i])>75):\n",
    "            continue\n",
    "        totalCount+=1\n",
    "        print(\"Actual:\", test_label[i],\"Guess:\",results[i],\"Delta\",element)\n",
    "        if element < threshold:\n",
    "            correctDirectionCount+=1\n",
    "    totalMAE += predAccuracy\n",
    "    print(\"Testing Accuracy:\", predAccuracy)\n",
    "    step+=1\n",
    "print(\"Total MAE: \", (totalMAE/(step-1)))\n",
    "print(\"Turn percentage\", (totalCount/((step-1) * batch_size)))\n",
    "print (\"Correct Speed within threshold percentage \",(correctDirectionCount/totalCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
